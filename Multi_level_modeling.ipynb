{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "name": "Multi_level_modeling.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aSVyBuq7LPct",
        "outputId": "1c970d6e-216c-4399-f89a-72c244d90f4a"
      },
      "source": [
        "# Install the OpenSlide C library and Python bindings\n",
        "# After installing these libraries, use `Runtime -> restart and run all` on the menu\n",
        "!apt-get install openslide-tools\n",
        "!pip install openslide-python"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Reading package lists... Done\n",
            "Building dependency tree       \n",
            "Reading state information... Done\n",
            "The following additional packages will be installed:\n",
            "  libopenslide0\n",
            "Suggested packages:\n",
            "  libtiff-tools\n",
            "The following NEW packages will be installed:\n",
            "  libopenslide0 openslide-tools\n",
            "0 upgraded, 2 newly installed, 0 to remove and 14 not upgraded.\n",
            "Need to get 92.5 kB of archives.\n",
            "After this operation, 268 kB of additional disk space will be used.\n",
            "Get:1 http://archive.ubuntu.com/ubuntu bionic/universe amd64 libopenslide0 amd64 3.4.1+dfsg-2 [79.8 kB]\n",
            "Get:2 http://archive.ubuntu.com/ubuntu bionic/universe amd64 openslide-tools amd64 3.4.1+dfsg-2 [12.7 kB]\n",
            "Fetched 92.5 kB in 0s (208 kB/s)\n",
            "Selecting previously unselected package libopenslide0.\n",
            "(Reading database ... 144865 files and directories currently installed.)\n",
            "Preparing to unpack .../libopenslide0_3.4.1+dfsg-2_amd64.deb ...\n",
            "Unpacking libopenslide0 (3.4.1+dfsg-2) ...\n",
            "Selecting previously unselected package openslide-tools.\n",
            "Preparing to unpack .../openslide-tools_3.4.1+dfsg-2_amd64.deb ...\n",
            "Unpacking openslide-tools (3.4.1+dfsg-2) ...\n",
            "Setting up libopenslide0 (3.4.1+dfsg-2) ...\n",
            "Setting up openslide-tools (3.4.1+dfsg-2) ...\n",
            "Processing triggers for libc-bin (2.27-3ubuntu1.2) ...\n",
            "/sbin/ldconfig.real: /usr/local/lib/python3.6/dist-packages/ideep4py/lib/libmkldnn.so.0 is not a symbolic link\n",
            "\n",
            "Processing triggers for man-db (2.8.3-2ubuntu0.1) ...\n",
            "Collecting openslide-python\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/03/da/12dc0e7566ace61a5a65244220458dcb656b09cbf18ca50f3098875d97e4/openslide-python-1.1.2.tar.gz (316kB)\n",
            "\u001b[K     |████████████████████████████████| 317kB 12.3MB/s \n",
            "\u001b[?25hRequirement already satisfied: Pillow in /usr/local/lib/python3.6/dist-packages (from openslide-python) (7.0.0)\n",
            "Building wheels for collected packages: openslide-python\n",
            "  Building wheel for openslide-python (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for openslide-python: filename=openslide_python-1.1.2-cp36-cp36m-linux_x86_64.whl size=26715 sha256=a2fa5bc8fd420b8c8dd1a1d244934ede383994324bcb2b781f7c0d6aa3d45968\n",
            "  Stored in directory: /root/.cache/pip/wheels/6b/55/74/ba9d3dcc2c5c0f1282e08bae70df0ed57b496fb6b5c8f1adc9\n",
            "Successfully built openslide-python\n",
            "Installing collected packages: openslide-python\n",
            "Successfully installed openslide-python-1.1.2\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bv1xdoXELUGQ"
      },
      "source": [
        "%matplotlib inline\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "from openslide import open_slide, __library_version__ as openslide_version\n",
        "import os\n",
        "from PIL import Image\n",
        "from skimage.color import rgb2gray\n",
        "import random\n",
        "import pandas as pd\n",
        "import tensorflow as tf\n",
        "from sklearn.metrics import classification_report"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "i7zudBw3LWzp",
        "outputId": "d5a75f23-dffe-46a2-f6c6-8f48a302d6e0"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CzNeu2tRLY2U"
      },
      "source": [
        "def make_dir(base_path, level):\n",
        "    level_dir = f'{base_path}{level}level'\n",
        "    if not os.path.exists(level_dir):\n",
        "        os.mkdir(level_dir)\n",
        "    train_image_dir = os.path.join(level_dir,'train_image/')\n",
        "    train_mask_dir = os.path.join(level_dir,'train_mask/')\n",
        "\n",
        "    val_image_dir = os.path.join(level_dir,'val_image/')\n",
        "    val_mask_dir = os.path.join(level_dir,'val_mask/')\n",
        "\n",
        "    test_image_dir = os.path.join(level_dir,'test_image/')\n",
        "    test_mask_dir = os.path.join(level_dir,'test_mask/')\n",
        "\n",
        "    if not os.path.exists(train_image_dir):\n",
        "        os.mkdir(train_image_dir)\n",
        "    if not os.path.exists(train_mask_dir):\n",
        "        os.mkdir(train_mask_dir)\n",
        "    if not os.path.exists(val_image_dir):\n",
        "        os.mkdir(val_image_dir)\n",
        "    if not os.path.exists(val_mask_dir):\n",
        "        os.mkdir(val_mask_dir)    \n",
        "    if not os.path.exists(test_image_dir):\n",
        "        os.mkdir(test_image_dir)\n",
        "    if not os.path.exists(test_mask_dir):\n",
        "        os.mkdir(test_mask_dir)\n",
        "    return(train_image_dir, train_mask_dir, val_image_dir, val_mask_dir, test_image_dir, test_mask_dir)"
      ],
      "execution_count": 33,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OiQh4L7ALZlI"
      },
      "source": [
        "base_path = '/content/'\n",
        "train_image_dir, train_mask_dir, val_image_dir, val_mask_dir, test_image_dir, test_mask_dir = make_dir(base_path, level = 'multi_')\n",
        "\n",
        "# train_image_dir5, train_mask_dir5, val_image_dir5, val_mask_dir5, test_image_dir5, test_mask_dir5 = make_dir(base_path, level = 5)\n",
        "# train_image_dir4, train_mask_dir4, val_image_dir4, val_mask_dir4, test_image_dir4, test_mask_dir4 = make_dir(base_path, level = 4)\n",
        "# train_image_dir3, train_mask_dir3, val_image_dir3, val_mask_dir3, test_image_dir3, test_mask_dir3 = make_dir(base_path, level = 3)"
      ],
      "execution_count": 34,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "M5MMROjVae1i",
        "outputId": "9794bf5d-4089-4155-8509-8277a96613c1"
      },
      "source": [
        "train_image_dir"
      ],
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'/content/multi_level/train_image/'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 35
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UeSbiAVnaWub"
      },
      "source": [
        "!unzip -q '/content/drive/MyDrive/Applied Deep Learning/project/multi_level/train_image.zip' -d /content/multi_level/train_image/\r\n",
        "!unzip -q '/content/drive/MyDrive/Applied Deep Learning/project/multi_level/val_image.zip' -d /content/multi_level/val_image/\r\n",
        "!unzip -q '/content/drive/MyDrive/Applied Deep Learning/project/multi_level/test_image.zip' -d /content/multi_level/test_image/"
      ],
      "execution_count": 36,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QdESyvjOa5GU"
      },
      "source": [
        "!cp '/content/drive/MyDrive/Applied Deep Learning/project/multi_level/multi_level_train_data.txt' /content/\r\n",
        "!cp '/content/drive/MyDrive/Applied Deep Learning/project/multi_level/multi_level_val_data.txt' /content/\r\n",
        "!cp '/content/drive/MyDrive/Applied Deep Learning/project/multi_level/multi_level_test_data.txt' /content/"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "y1iWS-bBbGsp"
      },
      "source": [
        "train_df = pd.read_csv('/content/multi_level_train_data.txt', header = None)\r\n",
        "val_df = pd.read_csv('/content/multi_level_val_data.txt', header = None)\r\n",
        "test_df = pd.read_csv('/content/multi_level_test_data.txt', header = None)\r\n",
        "cols = ['Low Res Image Paths', 'High Res Image Paths', 'Low Res Xoffset', 'Low Res Yoffset', 'High Res Xoffset', \r\n",
        "                                                     'High Res Yoffset', 'Labels', 'slide code', 'Low Res Level', 'High Res Level']\r\n",
        "train_df.columns, val_df.columns, test_df.columns = cols, cols, cols\r\n",
        "\r\n",
        "train_df = train_df.sample(frac=1).reset_index(drop=True)\r\n",
        "val_df = val_df.sample(frac=1).reset_index(drop=True)\r\n",
        "test_df = test_df.sample(frac=1).reset_index(drop=True)\r\n",
        "\r\n",
        "train_df['Labels'] = train_df['Labels'].astype(str)\r\n",
        "val_df['Labels'] = val_df['Labels'].astype(str)\r\n",
        "test_df['Labels'] = test_df['Labels'].astype(str)\r\n"
      ],
      "execution_count": 51,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 203
        },
        "id": "hHrlvoBNf29k",
        "outputId": "7a507cc1-18c8-4cce-ed87-71094f9e69dc"
      },
      "source": [
        "train_df.head()"
      ],
      "execution_count": 48,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Low Res Image Paths</th>\n",
              "      <th>High Res Image Paths</th>\n",
              "      <th>Low Res Xoffset</th>\n",
              "      <th>Low Res Yoffset</th>\n",
              "      <th>High Res Xoffset</th>\n",
              "      <th>High Res Yoffset</th>\n",
              "      <th>Labels</th>\n",
              "      <th>slide code</th>\n",
              "      <th>Low Res Level</th>\n",
              "      <th>High Res Level</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>/content/multi_level/train_image/normal/slide0...</td>\n",
              "      <td>/content/multi_level/train_image/normal/slide0...</td>\n",
              "      <td>1408</td>\n",
              "      <td>3840</td>\n",
              "      <td>2964</td>\n",
              "      <td>7828</td>\n",
              "      <td>0</td>\n",
              "      <td>84</td>\n",
              "      <td>4</td>\n",
              "      <td>3</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>/content/multi_level/train_image/normal/slide0...</td>\n",
              "      <td>/content/multi_level/train_image/normal/slide0...</td>\n",
              "      <td>1920</td>\n",
              "      <td>8704</td>\n",
              "      <td>3988</td>\n",
              "      <td>17556</td>\n",
              "      <td>0</td>\n",
              "      <td>5</td>\n",
              "      <td>4</td>\n",
              "      <td>3</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>/content/multi_level/train_image/normal/slide0...</td>\n",
              "      <td>/content/multi_level/train_image/normal/slide0...</td>\n",
              "      <td>4736</td>\n",
              "      <td>8320</td>\n",
              "      <td>9620</td>\n",
              "      <td>16788</td>\n",
              "      <td>0</td>\n",
              "      <td>64</td>\n",
              "      <td>4</td>\n",
              "      <td>3</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>/content/multi_level/train_image/normal/slide0...</td>\n",
              "      <td>/content/multi_level/train_image/normal/slide0...</td>\n",
              "      <td>640</td>\n",
              "      <td>896</td>\n",
              "      <td>1428</td>\n",
              "      <td>1940</td>\n",
              "      <td>0</td>\n",
              "      <td>75</td>\n",
              "      <td>4</td>\n",
              "      <td>3</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>/content/multi_level/train_image/normal/slide0...</td>\n",
              "      <td>/content/multi_level/train_image/normal/slide0...</td>\n",
              "      <td>1920</td>\n",
              "      <td>1280</td>\n",
              "      <td>3988</td>\n",
              "      <td>2708</td>\n",
              "      <td>0</td>\n",
              "      <td>91</td>\n",
              "      <td>4</td>\n",
              "      <td>3</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                 Low Res Image Paths  ... High Res Level\n",
              "0  /content/multi_level/train_image/normal/slide0...  ...              3\n",
              "1  /content/multi_level/train_image/normal/slide0...  ...              3\n",
              "2  /content/multi_level/train_image/normal/slide0...  ...              3\n",
              "3  /content/multi_level/train_image/normal/slide0...  ...              3\n",
              "4  /content/multi_level/train_image/normal/slide0...  ...              3\n",
              "\n",
              "[5 rows x 10 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 48
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YFan6bIzlOni",
        "outputId": "3b9d32fd-98b1-49b8-9971-16ce6d3b8b2b"
      },
      "source": [
        "train_df.shape"
      ],
      "execution_count": 69,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(6440, 10)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 69
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jsJP-MyinSKT"
      },
      "source": [
        "# def data_generator_aug(df, train_image_dir):\r\n",
        "#     train_datagen = ImageDataGenerator(\r\n",
        "#         rescale=1./255,\r\n",
        "#         rotation_range=90,\r\n",
        "#         # width_shift_range=0.2,\r\n",
        "#         # height_shift_range=0.2,\r\n",
        "#         # shear_range=0.2,\r\n",
        "#         # zoom_range=0.2,\r\n",
        "#         horizontal_flip=True)\r\n",
        "#     train_generator1 = train_datagen.flow_from_dataframe(\r\n",
        "#         dataframe = train_df,\r\n",
        "#         directory = train_image_dir,\r\n",
        "#         x_col = 'Low Res Image Paths',\r\n",
        "#         y_col = 'Labels',\r\n",
        "#         target_size = (IMG_SIZE, IMG_SIZE),\r\n",
        "#         batch_size = batch_size,\r\n",
        "#         class_mode = 'binary',\r\n",
        "#         shuffle=False\r\n",
        "#     )\r\n",
        "#     train_generator2 = train_datagen.flow_from_dataframe(\r\n",
        "#         dataframe = train_df,\r\n",
        "#         directory = train_image_dir,\r\n",
        "#         x_col = 'High Res Image Paths',\r\n",
        "#         y_col = 'Labels',\r\n",
        "#         target_size = (IMG_SIZE, IMG_SIZE),\r\n",
        "#         batch_size = batch_size,\r\n",
        "#         class_mode = 'binary',\r\n",
        "#         shuffle=False\r\n",
        "#     )\r\n",
        "#     while True:\r\n",
        "#         yield([next(train_generator1)[0], next(train_generator2)[0]], next(train_generator1)[1])\r\n",
        "# combine_generator = data_generator_aug(train_df, train_image_dir)"
      ],
      "execution_count": 85,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "V2fP92COftSx"
      },
      "source": [
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\r\n",
        "def data_generator_aug(train_df, val_df, test_df, resolution = 'Low Res Image Paths'):\r\n",
        "    # train set\r\n",
        "    train_datagen = ImageDataGenerator(\r\n",
        "        rescale=1./255,\r\n",
        "        rotation_range=90,\r\n",
        "        # width_shift_range=0.2,\r\n",
        "        # height_shift_range=0.2,\r\n",
        "        # shear_range=0.2,\r\n",
        "        # zoom_range=0.2,\r\n",
        "        horizontal_flip=True)\r\n",
        "    test_datagen = ImageDataGenerator(rescale = 1./255)\r\n",
        "    # train set\r\n",
        "    train_generator = train_datagen.flow_from_dataframe(\r\n",
        "        dataframe = train_df,\r\n",
        "        directory = train_image_dir,\r\n",
        "        x_col = resolution,\r\n",
        "        y_col = 'Labels',\r\n",
        "        target_size = (IMG_SIZE, IMG_SIZE),\r\n",
        "        batch_size = batch_size,\r\n",
        "        class_mode = 'binary',\r\n",
        "        shuffle=False\r\n",
        "    )\r\n",
        "    validation_generator = test_datagen.flow_from_dataframe(\r\n",
        "        dataframe = val_df,\r\n",
        "        directory = val_image_dir,\r\n",
        "        x_col = resolution,\r\n",
        "        y_col = 'Labels',\r\n",
        "        target_size = (IMG_SIZE, IMG_SIZE),\r\n",
        "        batch_size = batch_size,\r\n",
        "        class_mode = 'binary',\r\n",
        "        shuffle=False\r\n",
        "    )\r\n",
        "\r\n",
        "    for data_batch, labels_batch in train_generator:\r\n",
        "        print('Train data: ')\r\n",
        "        print('data batch shape:', data_batch.shape)\r\n",
        "        print('labels batch shape:', labels_batch.shape)\r\n",
        "        break\r\n",
        "\r\n",
        "    for data_batch, labels_batch in validation_generator:\r\n",
        "        print('\\n')\r\n",
        "        print('Validation data: ')\r\n",
        "        print('data batch shape:', data_batch.shape)\r\n",
        "        print('labels batch shape:', labels_batch.shape)\r\n",
        "        break\r\n",
        "    # test set\r\n",
        "    test_generator = test_datagen.flow_from_dataframe(\r\n",
        "        dataframe = test_df,\r\n",
        "        directory = test_image_dir,\r\n",
        "        x_col = resolution,\r\n",
        "        y_col = 'Labels',\r\n",
        "        target_size = (IMG_SIZE, IMG_SIZE),\r\n",
        "        batch_size = batch_size,\r\n",
        "        class_mode = 'binary',\r\n",
        "        shuffle = False\r\n",
        "    )\r\n",
        "    return(train_generator, validation_generator, test_generator)"
      ],
      "execution_count": 74,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mbSwgLu9LoWb"
      },
      "source": [
        "# Multi-level Model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "j1b8BGB_h_RS",
        "outputId": "8e53cece-c86e-4b00-e9e7-b9cb8466b5cc"
      },
      "source": [
        "IMG_SIZE = 299\r\n",
        "batch_size = 32\r\n",
        "print('Low Res Images')\r\n",
        "level4_train_generator, level4_validation_generator, level4_test_generator = data_generator_aug(train_df, val_df, test_df)\r\n",
        "print()\r\n",
        "print('High Res Images')\r\n",
        "level3_train_generator, level3_validation_generator, level3_test_generator = data_generator_aug(train_df, val_df, test_df, 'High Res Image Paths')"
      ],
      "execution_count": 76,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Low Res Images\n",
            "Found 6440 validated image filenames belonging to 2 classes.\n",
            "Found 1458 validated image filenames belonging to 2 classes.\n",
            "Train data: \n",
            "data batch shape: (32, 299, 299, 3)\n",
            "labels batch shape: (32,)\n",
            "\n",
            "\n",
            "Validation data: \n",
            "data batch shape: (32, 299, 299, 3)\n",
            "labels batch shape: (32,)\n",
            "Found 1274 validated image filenames belonging to 2 classes.\n",
            "\n",
            "High Res Images\n",
            "Found 6440 validated image filenames belonging to 2 classes.\n",
            "Found 1458 validated image filenames belonging to 2 classes.\n",
            "Train data: \n",
            "data batch shape: (32, 299, 299, 3)\n",
            "labels batch shape: (32,)\n",
            "\n",
            "\n",
            "Validation data: \n",
            "data batch shape: (32, 299, 299, 3)\n",
            "labels batch shape: (32,)\n",
            "Found 1274 validated image filenames belonging to 2 classes.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YCtasDMDLZSN"
      },
      "source": [
        "def combine_generator(gen1, gen2):\n",
        "    while True:\n",
        "        yield([next(gen1)[0], next(gen2)[0]], next(gen1)[1])"
      ],
      "execution_count": 77,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IuRUKNvMLwMz"
      },
      "source": [
        "multi_train_generator = combine_generator(level3_train_generator, level4_train_generator)\n",
        "multi_val_generator = combine_generator(level3_validation_generator, level4_validation_generator)\n",
        "multi_test_generator = combine_generator(level3_test_generator, level4_test_generator)"
      ],
      "execution_count": 78,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "M6ME8s2FLye8",
        "outputId": "95a8e4ab-1bf0-4b74-b6e1-0c48af2863e6"
      },
      "source": [
        "IMG_SIZE = 299\n",
        "vgg_base_1 = tf.keras.applications.VGG16(\n",
        "            include_top = False,\n",
        "            weights = 'imagenet',\n",
        "            input_shape = (IMG_SIZE, IMG_SIZE, 3),\n",
        "            pooling = None,\n",
        "            classes = 2,\n",
        "            classifier_activation = 'softmax',\n",
        "        )\n",
        "vgg_base_2 = tf.keras.applications.VGG16(\n",
        "            include_top = False,\n",
        "            weights = 'imagenet',\n",
        "            input_shape = (IMG_SIZE, IMG_SIZE, 3),\n",
        "            pooling = None,\n",
        "            classes = 2,\n",
        "            classifier_activation = 'softmax',\n",
        "        )\n",
        "vgg_base_1.trainable = False\n",
        "vgg_base_2.trainable = False\n",
        "\n",
        "\n",
        "high_res_level_input = tf.keras.layers.Input(shape=(IMG_SIZE, IMG_SIZE, 3))\n",
        "low_res_level_input = tf.keras.layers.Input(shape=(IMG_SIZE, IMG_SIZE, 3))\n",
        "\n",
        "# high resolution level\n",
        "high_res_vgg = tf.keras.Sequential([\n",
        "    vgg_base_1,\n",
        "    tf.keras.layers.GlobalAveragePooling2D(),\n",
        "    tf.keras.layers.Flatten(),\n",
        "    tf.keras.layers.Dense(128, activation='relu')\n",
        "])\n",
        "high_res_vgg_output = high_res_vgg(high_res_level_input)\n",
        "\n",
        "# low resolution level\n",
        "low_res_vgg = tf.keras.Sequential([\n",
        "    vgg_base_2,\n",
        "    tf.keras.layers.GlobalAveragePooling2D(),\n",
        "    tf.keras.layers.Flatten(),\n",
        "    tf.keras.layers.Dense(128, activation='relu'),\n",
        "])\n",
        "low_res_vgg_output = low_res_vgg(low_res_level_input)\n",
        "\n",
        "# concatenate two output layers as input\n",
        "concatenated_input = tf.keras.layers.concatenate([high_res_vgg_output, low_res_vgg_output])\n",
        "flattened = tf.keras.layers.Flatten()(concatenated_input)\n",
        "\n",
        "output = tf.keras.layers.Dense(128, activation=\"relu\")(flattened)\n",
        "output = tf.keras.layers.Dropout(0.4)(output)\n",
        "output = tf.keras.layers.Dense(2, activation=\"softmax\")(output)\n",
        "\n",
        "vgg_multi_resolution_model = tf.keras.Model(inputs=[high_res_level_input, low_res_level_input], outputs=output)\n",
        "vgg_multi_resolution_model.summary()\n",
        "\n",
        "vgg_multi_resolution_model.compile(optimizer = tf.keras.optimizers.Adam(learning_rate=0.001),\n",
        "                                   loss = 'sparse_categorical_crossentropy',\n",
        "                                   metrics = ['accuracy'])"
      ],
      "execution_count": 79,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"model_1\"\n",
            "__________________________________________________________________________________________________\n",
            "Layer (type)                    Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            "input_7 (InputLayer)            [(None, 299, 299, 3) 0                                            \n",
            "__________________________________________________________________________________________________\n",
            "input_8 (InputLayer)            [(None, 299, 299, 3) 0                                            \n",
            "__________________________________________________________________________________________________\n",
            "sequential_2 (Sequential)       (None, 128)          14780352    input_7[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "sequential_3 (Sequential)       (None, 128)          14780352    input_8[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_1 (Concatenate)     (None, 256)          0           sequential_2[0][0]               \n",
            "                                                                 sequential_3[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "flatten_5 (Flatten)             (None, 256)          0           concatenate_1[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "dense_6 (Dense)                 (None, 128)          32896       flatten_5[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "dropout_1 (Dropout)             (None, 128)          0           dense_6[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "dense_7 (Dense)                 (None, 2)            258         dropout_1[0][0]                  \n",
            "==================================================================================================\n",
            "Total params: 29,593,858\n",
            "Trainable params: 164,482\n",
            "Non-trainable params: 29,429,376\n",
            "__________________________________________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 661
        },
        "id": "NsWEdfMYL0H2",
        "outputId": "dc3d5e43-4718-4de6-e9fe-f81dcfda04f9"
      },
      "source": [
        "tf.keras.utils.plot_model(vgg_multi_resolution_model)"
      ],
      "execution_count": 56,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<IPython.core.display.Image object>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 56
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZunFcLh_L1gI"
      },
      "source": [
        "if not os.path.exists('/content/checkpoint'):\n",
        "  os.mkdir('/content/checkpoint')\n",
        "if not os.path.exists('/content/checkpoint/VGG'):\n",
        "  os.mkdir('/content/checkpoint/VGG')\n",
        "multi_vgg_checkpoint_path = '/content/checkpoint/VGG/multi_level_weights-improvement-{epoch:02d}-{val_accuracy:.2f}-{val_loss:.2f}.hdf5'\n",
        "vgg_checkpoint_callback = tf.keras.callbacks.ModelCheckpoint(multi_vgg_checkpoint_path, \n",
        "                                                                    monitor='val_loss', \n",
        "                                                                    save_best_only=True, \n",
        "                                                                    mode='auto')\n",
        "\n",
        "vgg_early_stop_callback = tf.keras.callbacks.EarlyStopping(\n",
        "                              monitor='val_loss', min_delta=0, patience=10)"
      ],
      "execution_count": 57,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZKu2X__9axvA",
        "outputId": "a9ae1580-6876-4886-c3f0-4cbbc59cfc44"
      },
      "source": [
        "for data_batch, labels_batch in multi_train_generator:\r\n",
        "    print('Train data: ')\r\n",
        "    print('data batch shape:', len(data_batch))\r\n",
        "    print('data batch', data_batch[0].shape)\r\n",
        "    print('data batch2', data_batch[1].shape)\r\n",
        "    print('labels batch shape:', labels_batch.shape)\r\n",
        "    break"
      ],
      "execution_count": 88,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Train data: \n",
            "data batch shape: 2\n",
            "data batch (32, 299, 299, 3)\n",
            "data batch2 (32, 299, 299, 3)\n",
            "labels batch shape: (32,)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 526
        },
        "id": "abYq-Jr2ZS3U",
        "outputId": "e2f8ddbc-0f2a-461e-a83b-f2c523bc67b5"
      },
      "source": [
        "epochs = 10\r\n",
        "multi_level_vgg_history = vgg_multi_resolution_model.fit(combine_generator, \r\n",
        "                                                          epochs=epochs)\r\n",
        "                                                          # steps_per_epoch = 256 // batch_size,\r\n",
        "                                                          # validation_data=multi_val_generator,\r\n",
        "                                                          # callbacks=[vgg_checkpoint_callback, \r\n",
        "                                                                    # vgg_early_stop_callback])"
      ],
      "execution_count": 87,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Found 6440 validated image filenames belonging to 2 classes.\n",
            "Found 6440 validated image filenames belonging to 2 classes.\n",
            "Epoch 1/10\n",
            "    100/Unknown - 184s 2s/step - loss: 0.3221 - accuracy: 0.9081"
          ],
          "name": "stdout"
        },
        {
          "output_type": "error",
          "ename": "InvalidArgumentError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mInvalidArgumentError\u001b[0m                      Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-87-75725eb5d6c4>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mepochs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m10\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m multi_level_vgg_history = vgg_multi_resolution_model.fit(combine_generator, \n\u001b[0;32m----> 3\u001b[0;31m                                                           epochs=epochs)\n\u001b[0m\u001b[1;32m      4\u001b[0m                                                           \u001b[0;31m# steps_per_epoch = 256 // batch_size,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m                                                           \u001b[0;31m# validation_data=multi_val_generator,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m   1098\u001b[0m                 _r=1):\n\u001b[1;32m   1099\u001b[0m               \u001b[0mcallbacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_train_batch_begin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1100\u001b[0;31m               \u001b[0mtmp_logs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1101\u001b[0m               \u001b[0;32mif\u001b[0m \u001b[0mdata_handler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshould_sync\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1102\u001b[0m                 \u001b[0mcontext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masync_wait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    826\u001b[0m     \u001b[0mtracing_count\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexperimental_get_tracing_count\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    827\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mtrace\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTrace\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_name\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mtm\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 828\u001b[0;31m       \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    829\u001b[0m       \u001b[0mcompiler\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"xla\"\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_experimental_compile\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;34m\"nonXla\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    830\u001b[0m       \u001b[0mnew_tracing_count\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexperimental_get_tracing_count\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m_call\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    853\u001b[0m       \u001b[0;31m# In this case we have created variables on the first call, so we run the\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    854\u001b[0m       \u001b[0;31m# defunned version which is guaranteed to never create variables.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 855\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_stateless_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# pylint: disable=not-callable\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    856\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_stateful_fn\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    857\u001b[0m       \u001b[0;31m# Release the lock early so that multiple threads can perform the call\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   2941\u001b[0m        filtered_flat_args) = self._maybe_define_function(args, kwargs)\n\u001b[1;32m   2942\u001b[0m     return graph_function._call_flat(\n\u001b[0;32m-> 2943\u001b[0;31m         filtered_flat_args, captured_inputs=graph_function.captured_inputs)  # pylint: disable=protected-access\n\u001b[0m\u001b[1;32m   2944\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2945\u001b[0m   \u001b[0;34m@\u001b[0m\u001b[0mproperty\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m_call_flat\u001b[0;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[1;32m   1917\u001b[0m       \u001b[0;31m# No tape is watching; skip to running the function.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1918\u001b[0m       return self._build_call_outputs(self._inference_function.call(\n\u001b[0;32m-> 1919\u001b[0;31m           ctx, args, cancellation_manager=cancellation_manager))\n\u001b[0m\u001b[1;32m   1920\u001b[0m     forward_backward = self._select_forward_and_backward_functions(\n\u001b[1;32m   1921\u001b[0m         \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36mcall\u001b[0;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[1;32m    558\u001b[0m               \u001b[0minputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    559\u001b[0m               \u001b[0mattrs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mattrs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 560\u001b[0;31m               ctx=ctx)\n\u001b[0m\u001b[1;32m    561\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    562\u001b[0m           outputs = execute.execute_with_cancellation(\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     58\u001b[0m     \u001b[0mctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mensure_initialized\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     59\u001b[0m     tensors = pywrap_tfe.TFE_Py_Execute(ctx._handle, device_name, op_name,\n\u001b[0;32m---> 60\u001b[0;31m                                         inputs, attrs, num_outputs)\n\u001b[0m\u001b[1;32m     61\u001b[0m   \u001b[0;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     62\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mname\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mInvalidArgumentError\u001b[0m:  Incompatible shapes: [32] vs. [8]\n\t [[node Equal (defined at <ipython-input-80-71a82a61059c>:7) ]] [Op:__inference_train_function_6253]\n\nFunction call stack:\ntrain_function\n"
          ]
        }
      ]
    }
  ]
}