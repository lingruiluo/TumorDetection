{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Multi-level modeling.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "aSVyBuq7LPct"
      },
      "source": [
        "# Install the OpenSlide C library and Python bindings\n",
        "# After installing these libraries, use `Runtime -> restart and run all` on the menu\n",
        "!apt-get install openslide-tools\n",
        "!pip install openslide-python"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bv1xdoXELUGQ"
      },
      "source": [
        "%matplotlib inline\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "from openslide import open_slide, __library_version__ as openslide_version\n",
        "import os\n",
        "from PIL import Image\n",
        "from skimage.color import rgb2gray\n",
        "import random\n",
        "import pandas as pd\n",
        "import tensorflow as tf\n",
        "from sklearn.metrics import classification_report"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "i7zudBw3LWzp"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CzNeu2tRLY2U"
      },
      "source": [
        "def make_dir(base_path, level):\n",
        "    level_dir = f'{base_path}level{level}'\n",
        "    if not os.path.exists(level_dir):\n",
        "        os.mkdir(level_dir)\n",
        "    train_image_dir = os.path.join(level_dir,'train_image/')\n",
        "    train_mask_dir = os.path.join(level_dir,'train_mask/')\n",
        "\n",
        "    val_image_dir = os.path.join(level_dir,'val_image/')\n",
        "    val_mask_dir = os.path.join(level_dir,'val_mask/')\n",
        "\n",
        "    test_image_dir = os.path.join(level_dir,'test_image/')\n",
        "    test_mask_dir = os.path.join(level_dir,'test_mask/')\n",
        "\n",
        "    if not os.path.exists(train_image_dir):\n",
        "        os.mkdir(train_image_dir)\n",
        "    if not os.path.exists(train_mask_dir):\n",
        "        os.mkdir(train_mask_dir)\n",
        "    if not os.path.exists(val_image_dir):\n",
        "        os.mkdir(val_image_dir)\n",
        "    if not os.path.exists(val_mask_dir):\n",
        "        os.mkdir(val_mask_dir)    \n",
        "    if not os.path.exists(test_image_dir):\n",
        "        os.mkdir(test_image_dir)\n",
        "    if not os.path.exists(test_mask_dir):\n",
        "        os.mkdir(test_mask_dir)\n",
        "    return(train_image_dir, train_mask_dir, val_image_dir, val_mask_dir, test_image_dir, test_mask_dir)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OiQh4L7ALZlI"
      },
      "source": [
        "base_path = '/content/'\n",
        "train_image_dir5, train_mask_dir5, val_image_dir5, val_mask_dir5, test_image_dir5, test_mask_dir5 = make_dir(base_path, level = 5)\n",
        "train_image_dir4, train_mask_dir4, val_image_dir4, val_mask_dir4, test_image_dir4, test_mask_dir4 = make_dir(base_path, level = 4)\n",
        "train_image_dir3, train_mask_dir3, val_image_dir3, val_mask_dir3, test_image_dir3, test_mask_dir3 = make_dir(base_path, level = 3)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nRoiAtHPLZi9"
      },
      "source": [
        "# create a folder called 'Applied Deep Learning' in the Google Drive\n",
        "\n",
        "!unzip -q '/content/drive/MyDrive/Applied Deep Learning/project/level4/train_mask.zip' -d /content/level4/train_mask/\n",
        "!unzip -q '/content/drive/MyDrive/Applied Deep Learning/project/level4/train_image.zip' -d /content/level4/train_image/\n",
        "!unzip -q '/content/drive/MyDrive/Applied Deep Learning/project/level4/val_mask.zip' -d /content/level4/val_mask/\n",
        "!unzip -q '/content/drive/MyDrive/Applied Deep Learning/project/level4/val_image.zip' -d /content/level4/val_image/\n",
        "!unzip -q '/content/drive/MyDrive/Applied Deep Learning/project/level4/test_mask.zip' -d /content/level4/test_mask/\n",
        "!unzip -q '/content/drive/MyDrive/Applied Deep Learning/project/level4/test_image.zip' -d /content/level4/test_image/\n",
        "\n",
        "!unzip -q '/content/drive/MyDrive/Applied Deep Learning/project/level5/train_mask.zip' -d /content/level5/train_mask/\n",
        "!unzip -q '/content/drive/MyDrive/Applied Deep Learning/project/level5/train_image.zip' -d /content/level5/train_image/\n",
        "!unzip -q '/content/drive/MyDrive/Applied Deep Learning/project/level5/val_mask.zip' -d /content/level5/val_mask/\n",
        "!unzip -q '/content/drive/MyDrive/Applied Deep Learning/project/level5/val_image.zip' -d /content/level5/val_image/\n",
        "!unzip -q '/content/drive/MyDrive/Applied Deep Learning/project/level5/test_mask.zip' -d /content/level5/test_mask/\n",
        "!unzip -q '/content/drive/MyDrive/Applied Deep Learning/project/level5/test_image.zip' -d /content/level5/test_image/\n",
        "\n",
        "!unzip -q '/content/drive/MyDrive/Applied Deep Learning/project/level3/train_mask.zip' -d /content/level3/train_mask/\n",
        "!unzip -q '/content/drive/MyDrive/Applied Deep Learning/project/level3/train_image.zip' -d /content/level3/train_image/\n",
        "!unzip -q '/content/drive/MyDrive/Applied Deep Learning/project/level3/val_mask.zip' -d /content/level3/val_mask/\n",
        "!unzip -q '/content/drive/MyDrive/Applied Deep Learning/project/level3/val_image.zip' -d /content/level3/val_image/\n",
        "!unzip -q '/content/drive/MyDrive/Applied Deep Learning/project/level3/test_mask.zip' -d /content/level3/test_mask/\n",
        "!unzip -q '/content/drive/MyDrive/Applied Deep Learning/project/level3/test_image.zip' -d /content/level3/test_image/"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XJ5OYjQVLZgs"
      },
      "source": [
        "!cp '/content/drive/MyDrive/Applied Deep Learning/project/level4/level4_train_data.txt' /content/\n",
        "!cp '/content/drive/MyDrive/Applied Deep Learning/project/level4/level4_val_data.txt' /content/\n",
        "!cp '/content/drive/MyDrive/Applied Deep Learning/project/level4/level4_test_data.txt' /content/\n",
        "\n",
        "!cp '/content/drive/MyDrive/Applied Deep Learning/project/level5/level5_train_data.txt' /content/\n",
        "!cp '/content/drive/MyDrive/Applied Deep Learning/project/level5/level5_val_data.txt' /content/\n",
        "!cp '/content/drive/MyDrive/Applied Deep Learning/project/level5/level5_test_data.txt' /content/\n",
        "\n",
        "!cp '/content/drive/MyDrive/Applied Deep Learning/project/level3/level3_train_data.txt' /content/\n",
        "!cp '/content/drive/MyDrive/Applied Deep Learning/project/level3/level3_val_data.txt' /content/\n",
        "!cp '/content/drive/MyDrive/Applied Deep Learning/project/level3/level3_test_data.txt' /content/"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FT07Mi2KLZeO"
      },
      "source": [
        "IMG_SIZE = 299\n",
        "batch_size = 32\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "\n",
        "# data generator\n",
        "def data_generator(train_image_dir, val_image_dir, test_image_dir):\n",
        "    train_datagen = ImageDataGenerator(rescale = 1./255)\n",
        "    test_datagen = ImageDataGenerator(rescale = 1./255)\n",
        "    # train set\n",
        "    train_generator = train_datagen.flow_from_directory(\n",
        "        train_image_dir,\n",
        "        target_size = (IMG_SIZE, IMG_SIZE),\n",
        "        batch_size = batch_size,\n",
        "        class_mode = 'binary',\n",
        "        shuffle=True\n",
        "    )\n",
        "    validation_generator = test_datagen.flow_from_directory(\n",
        "        val_image_dir, \n",
        "        target_size = (IMG_SIZE, IMG_SIZE),\n",
        "        batch_size = batch_size,\n",
        "        class_mode = 'binary',\n",
        "        shuffle=True\n",
        "    )\n",
        "\n",
        "    for data_batch, labels_batch in train_generator:\n",
        "        print('Train data: ')\n",
        "        print('data batch shape:', data_batch.shape)\n",
        "        print('labels batch shape:', labels_batch.shape)\n",
        "        break\n",
        "\n",
        "    for data_batch, labels_batch in validation_generator:\n",
        "        print('\\n')\n",
        "        print('Validation data: ')\n",
        "        print('data batch shape:', data_batch.shape)\n",
        "        print('labels batch shape:', labels_batch.shape)\n",
        "        break\n",
        "    # test set\n",
        "    test_generator = test_datagen.flow_from_directory(\n",
        "        test_image_dir,\n",
        "        target_size = (IMG_SIZE, IMG_SIZE),\n",
        "        batch_size = batch_size,\n",
        "        class_mode = 'binary',\n",
        "        shuffle = True\n",
        "    )\n",
        "    return(train_generator, validation_generator, test_generator)\n",
        "\n",
        "# data generator with augmentation\n",
        "def data_generator_aug(train_image_dir, val_image_dir, test_image_dir):\n",
        "    # train set\n",
        "    train_datagen = ImageDataGenerator(\n",
        "        rescale=1./255,\n",
        "        rotation_range=90,\n",
        "        # width_shift_range=0.2,\n",
        "        # height_shift_range=0.2,\n",
        "        # shear_range=0.2,\n",
        "        # zoom_range=0.2,\n",
        "        horizontal_flip=True,\n",
        "        validation_split=0.2)\n",
        "    test_datagen = ImageDataGenerator(rescale = 1./255)\n",
        "    # train set\n",
        "    train_generator = train_datagen.flow_from_directory(\n",
        "        train_image_dir,\n",
        "        target_size = (IMG_SIZE, IMG_SIZE),\n",
        "        batch_size = batch_size,\n",
        "        class_mode = 'binary',\n",
        "        shuffle=True\n",
        "    )\n",
        "    validation_generator = test_datagen.flow_from_directory(\n",
        "        val_image_dir, \n",
        "        target_size = (IMG_SIZE, IMG_SIZE),\n",
        "        batch_size = batch_size,\n",
        "        class_mode = 'binary',\n",
        "        shuffle=True\n",
        "    )\n",
        "\n",
        "    for data_batch, labels_batch in train_generator:\n",
        "        print('Train data: ')\n",
        "        print('data batch shape:', data_batch.shape)\n",
        "        print('labels batch shape:', labels_batch.shape)\n",
        "        break\n",
        "\n",
        "    for data_batch, labels_batch in validation_generator:\n",
        "        print('\\n')\n",
        "        print('Validation data: ')\n",
        "        print('data batch shape:', data_batch.shape)\n",
        "        print('labels batch shape:', labels_batch.shape)\n",
        "        break\n",
        "    # test set\n",
        "    test_generator = test_datagen.flow_from_directory(\n",
        "        test_image_dir,\n",
        "        target_size = (IMG_SIZE, IMG_SIZE),\n",
        "        batch_size = batch_size,\n",
        "        class_mode = 'binary',\n",
        "        shuffle = True\n",
        "    )\n",
        "    return(train_generator, validation_generator, test_generator)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mbSwgLu9LoWb"
      },
      "source": [
        "# Multi-level Model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PVWNJIFGLZbf"
      },
      "source": [
        "print('level 4')\n",
        "level4_train_generator, level4_validation_generator, level4_test_generator = data_generator_aug(train_image_dir4, \n",
        "                                                                                                val_image_dir4, \n",
        "                                                                                                test_image_dir4)\n",
        "print()\n",
        "print('level 3')\n",
        "level3_train_generator, level3_validation_generator, level3_test_generator = data_generator_aug(train_image_dir3, \n",
        "                                                                                                val_image_dir3, \n",
        "                                                                                                test_image_dir3)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YCtasDMDLZSN"
      },
      "source": [
        "# def combine_generator(gen1, gen2):\n",
        "#     while True:\n",
        "#         yield(next(gen1), next(gen2))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IuRUKNvMLwMz"
      },
      "source": [
        "# multi_train_generator = combine_generator(level3_train_generator, level4_train_generator)\n",
        "# multi_val_generator = combine_generator(level3_validation_generator, level4_validation_generator)\n",
        "# multi_test_generator = combine_generator(level3_test_generator, level4_test_generator)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "M6ME8s2FLye8"
      },
      "source": [
        "IMG_SIZE = 299\n",
        "vgg_base_1 = tf.keras.applications.VGG16(\n",
        "            include_top = False,\n",
        "            weights = 'imagenet',\n",
        "            input_shape = (IMG_SIZE, IMG_SIZE, 3),\n",
        "            pooling = None,\n",
        "            classes = 2,\n",
        "            classifier_activation = 'softmax',\n",
        "        )\n",
        "vgg_base_2 = tf.keras.applications.VGG16(\n",
        "            include_top = False,\n",
        "            weights = 'imagenet',\n",
        "            input_shape = (IMG_SIZE, IMG_SIZE, 3),\n",
        "            pooling = None,\n",
        "            classes = 2,\n",
        "            classifier_activation = 'softmax',\n",
        "        )\n",
        "vgg_base_1.trainable = False\n",
        "vgg_base_2.trainable = False\n",
        "\n",
        "\n",
        "high_res_level_input = tf.keras.layers.Input(shape=(IMG_SIZE, IMG_SIZE, 3))\n",
        "low_res_level_input = tf.keras.layers.Input(shape=(IMG_SIZE, IMG_SIZE, 3))\n",
        "\n",
        "# high resolution level\n",
        "high_res_vgg = tf.keras.Sequential([\n",
        "    vgg_base_1,\n",
        "    tf.keras.layers.GlobalAveragePooling2D(),\n",
        "    tf.keras.layers.Dense(128, activation='relu')\n",
        "])\n",
        "high_res_vgg_output = high_res_vgg(high_res_level_input)\n",
        "\n",
        "# low resolution level\n",
        "low_res_vgg = tf.keras.Sequential([\n",
        "    vgg_base_2,\n",
        "    tf.keras.layers.GlobalAveragePooling2D(),\n",
        "    tf.keras.layers.Dense(128, activation='relu')\n",
        "])\n",
        "low_res_vgg_output = low_res_vgg(low_res_level_input)\n",
        "\n",
        "# concatenate two output layers as input\n",
        "concatenated_input = tf.keras.layers.concatenate([high_res_vgg_output, low_res_vgg_output])\n",
        "flattened = tf.keras.layers.Flatten()(concatenated_input)\n",
        "\n",
        "output = tf.keras.layers.Dense(128, activation=\"relu\")(flattened)\n",
        "output = tf.keras.layers.Dropout(0.4)(output)\n",
        "output = tf.keras.layers.Dense(2, activation=\"softmax\")(output)\n",
        "\n",
        "vgg_multi_resolution_model = tf.keras.Model(inputs=[high_res_level_input, low_res_level_input], outputs=output)\n",
        "vgg_multi_resolution_model.summary()\n",
        "\n",
        "vgg_multi_resolution_model.compile(optimizer = tf.keras.optimizers.Adam(learning_rate=0.001),\n",
        "                                   loss = 'sparse_categorical_crossentropy',\n",
        "                                   metrics = ['accuracy'])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NsWEdfMYL0H2"
      },
      "source": [
        "tf.keras.utils.plot_model(vgg_multi_resolution_model)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZunFcLh_L1gI"
      },
      "source": [
        "if not os.path.exists('/content/checkpoint'):\n",
        "  os.mkdir('/content/checkpoint')\n",
        "if not os.path.exists('/content/checkpoint/VGG'):\n",
        "  os.mkdir('/content/checkpoint/VGG')\n",
        "multi_vgg_checkpoint_path = '/content/checkpoint/VGG/multi_level_weights-improvement-{epoch:02d}-{val_accuracy:.2f}-{val_loss:.2f}.hdf5'\n",
        "vgg_checkpoint_callback = tf.keras.callbacks.ModelCheckpoint(multi_vgg_checkpoint_path, \n",
        "                                                                    monitor='val_loss', \n",
        "                                                                    save_best_only=True, \n",
        "                                                                    mode='auto')\n",
        "\n",
        "vgg_early_stop_callback = tf.keras.callbacks.EarlyStopping(\n",
        "                              monitor='val_loss', min_delta=0, patience=10)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SA7lMN9ZL3Xe"
      },
      "source": [
        "epochs = 10\n",
        "multi_level_vgg_history = vgg_multi_resolution_model.fit(multi_train_generator, \n",
        "                                                          epochs=epochs, \n",
        "                                                          validation_data=multi_val_generator,\n",
        "                                                          callbacks=[vgg_checkpoint_callback, \n",
        "                                                                    vgg_early_stop_callback])"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}